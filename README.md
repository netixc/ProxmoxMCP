# ğŸš€ Proxmox Manager - Proxmox MCP Server


A Python-based Model Context Protocol (MCP) server for interacting with Proxmox hypervisors, providing a clean interface for managing nodes, VMs, and containers.

## âœ¨ Features

- ğŸ¤– Full integration with Cline
- ğŸ› ï¸ Built with the official MCP SDK
- ğŸ”’ Secure token-based authentication with Proxmox
- ğŸ–¥ï¸ Tools for managing nodes, VMs, and LXC containers
- ğŸ’» VM and container console command execution
- ğŸ”§ Host command execution via SSH
- ğŸ“ Configurable logging system
- âœ… Type-safe implementation with Pydantic
- ğŸ¨ Rich output formatting with customizable themes




## ğŸ“¦ Installation

### Prerequisites
- UV package manager (recommended)
- Python 3.10 or higher
- Git
- Access to a Proxmox server with API token credentials

Before starting, ensure you have:
- [ ] Proxmox server hostname or IP
- [ ] Proxmox API token (see [API Token Setup](#proxmox-api-token-setup))
- [ ] UV installed (`pip install uv`)

### Quick Install

1. Clone and set up environment:
   ```bash
   # Clone repository
   git clone https://github.com/netixc/ProxmoxMCP.git
   cd ProxmoxMCP

   # Create and activate virtual environment
   uv venv
   source .venv/bin/activate  # Linux/macOS
   ```

2. Install dependencies:
   ```bash
   # Install with development dependencies
   uv pip install -e ".[dev]"
   ```

3. Create configuration:
   ```bash
   # Create config directory and copy template
   mkdir -p proxmox-config
   cp proxmox-config/config.example.json proxmox-config/config.json
   ```

4. Edit `proxmox-config/config.json`:
   ```json
   {
       "proxmox": {
           "host": "PROXMOX_HOST",        # Required: Your Proxmox server address
           "port": 8006,                  # Optional: Default is 8006
           "verify_ssl": false,           # Optional: Set false for self-signed certs
           "service": "PVE"               # Optional: Default is PVE
       },
       "auth": {
           "user": "USER@pve",            # Required: Your Proxmox username
           "token_name": "TOKEN_NAME",    # Required: API token ID
           "token_value": "TOKEN_VALUE"   # Required: API token value
       },
       "logging": {
           "level": "INFO",               # Optional: DEBUG for more detail
           "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
           "file": "proxmox_mcp.log"      # Optional: Log to file
       },
       "ssh": {                           # Optional: Required for container/host commands
           "username": "root",            # Optional: Default is "root"
           "port": 22,                    # Optional: Default is 22
           "key_file": "/path/to/ssh/key", # Optional: SSH private key path
           "password": "password",        # Optional: SSH password (not recommended)
           "timeout": 30                  # Optional: Connection timeout in seconds
       }
   }
   ```

### Verifying Installation

1. Check Python environment:
   ```bash
   python -c "import proxmox_mcp; print('Installation OK')"
   ```

2. Run the tests:
   ```bash
   pytest
   ```

3. Verify configuration:
   ```bash
   # Linux/macOS
   PROXMOX_MCP_CONFIG="proxmox-config/config.json" python -m proxmox_mcp.server
   ```

   You should see either:
   - A successful connection to your Proxmox server
   - Or a connection error (if Proxmox details are incorrect)

## âš™ï¸ Configuration

### Proxmox API Token Setup
1. Log into your Proxmox web interface
2. Navigate to Datacenter -> Permissions -> API Tokens
3. Create a new API token:
   - Select a user (e.g., root@pam)
   - Enter a token ID (e.g., "mcp-token")
   - Uncheck "Privilege Separation" if you want full access
   - Save and copy both the token ID and secret


### MCP Client Configuration

 Add to your MCP settings:
```json
{
  "mcpServers": {
    "proxmox": {
      "command": "/absolute/path/to/ProxmoxMCP/run-server.sh"
    }
  }
}
```



# ğŸ”§ Available Tools

The server provides the following MCP tools for interacting with Proxmox:

### get_nodes
Lists all nodes in the Proxmox cluster.

- Parameters: None
- Example Response:
  ```
  ğŸ–¥ï¸ Proxmox Nodes

  ğŸ–¥ï¸ pve-compute-01
    â€¢ Status: ONLINE
    â€¢ Uptime: â³ 156d 12h
    â€¢ CPU Cores: 64
    â€¢ Memory: 186.5 GB / 512.0 GB (36.4%)

  ğŸ–¥ï¸ pve-compute-02
    â€¢ Status: ONLINE
    â€¢ Uptime: â³ 156d 11h
    â€¢ CPU Cores: 64
    â€¢ Memory: 201.3 GB / 512.0 GB (39.3%)
  ```

### get_node_status
Get detailed status of a specific node.

- Parameters:
  - `node` (string, required): Name of the node
- Example Response:
  ```
  ğŸ–¥ï¸ Node: pve-compute-01
    â€¢ Status: ONLINE
    â€¢ Uptime: â³ 156d 12h
    â€¢ CPU Usage: 42.3%
    â€¢ CPU Cores: 64 (AMD EPYC 7763)
    â€¢ Memory: 186.5 GB / 512.0 GB (36.4%)
    â€¢ Network: â¬†ï¸ 12.8 GB/s â¬‡ï¸ 9.2 GB/s
    â€¢ Temperature: 38Â°C
  ```

### get_vms
List all VMs across the cluster.

- Parameters: None
- Example Response:
  ```
  ğŸ—ƒï¸ Virtual Machines

  ğŸ—ƒï¸ prod-db-master (ID: 100)
    â€¢ Status: RUNNING
    â€¢ Node: pve-compute-01
    â€¢ CPU Cores: 16
    â€¢ Memory: 92.3 GB / 128.0 GB (72.1%)

  ğŸ—ƒï¸ prod-web-01 (ID: 102)
    â€¢ Status: RUNNING
    â€¢ Node: pve-compute-01
    â€¢ CPU Cores: 8
    â€¢ Memory: 12.8 GB / 32.0 GB (40.0%)
  ```

### get_storage
List available storage.

- Parameters: None
- Example Response:
  ```
  ğŸ’¾ Storage Pools

  ğŸ’¾ ceph-prod
    â€¢ Status: ONLINE
    â€¢ Type: rbd
    â€¢ Usage: 12.8 TB / 20.0 TB (64.0%)
    â€¢ IOPS: â¬†ï¸ 15.2k â¬‡ï¸ 12.8k

  ğŸ’¾ local-zfs
    â€¢ Status: ONLINE
    â€¢ Type: zfspool
    â€¢ Usage: 3.2 TB / 8.0 TB (40.0%)
    â€¢ IOPS: â¬†ï¸ 42.8k â¬‡ï¸ 35.6k
  ```

### get_cluster_status
Get overall cluster status.

- Parameters: None
- Example Response:
  ```
  âš™ï¸ Proxmox Cluster

    â€¢ Name: enterprise-cloud
    â€¢ Status: HEALTHY
    â€¢ Quorum: OK
    â€¢ Nodes: 4 ONLINE
    â€¢ Version: 8.1.3
    â€¢ HA Status: ACTIVE
    â€¢ Resources:
      - Total CPU Cores: 192
      - Total Memory: 1536 GB
      - Total Storage: 70 TB
    â€¢ Workload:
      - Running VMs: 7
      - Total VMs: 8
      - Average CPU Usage: 38.6%
      - Average Memory Usage: 42.8%
  ```

### get_containers
List all LXC containers across the cluster.

- Parameters: None
- Example Response:
  ```
  ğŸ“¦ LXC Containers

  ğŸ“¦ prod-redis (ID: 200)
    â€¢ Status: RUNNING
    â€¢ Node: pve-compute-01
    â€¢ Template: ubuntu-22.04
    â€¢ CPU Cores: 4
    â€¢ Memory: 8.0 GB / 16.0 GB (50.0%)

  ğŸ“¦ dev-database (ID: 201)
    â€¢ Status: STOPPED
    â€¢ Node: pve-compute-02
    â€¢ Template: debian-12
    â€¢ CPU Cores: 2
    â€¢ Memory: 0.0 GB / 8.0 GB (0.0%)
  ```

### execute_vm_command
Execute a command in a VM's console using QEMU Guest Agent.

- Parameters:
  - `node` (string, required): Name of the node where VM is running
  - `vmid` (string, required): ID of the VM
  - `command` (string, required): Command to execute
- Example Response:
  ```
  ğŸ”§ Console Command Result
    â€¢ Status: SUCCESS
    â€¢ Command: systemctl status nginx
    â€¢ Node: pve-compute-01
    â€¢ VM: prod-web-01 (ID: 102)

  Output:
  â— nginx.service - A high performance web server and a reverse proxy server
     Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)
     Active: active (running) since Tue 2025-02-18 15:23:45 UTC; 2 months 3 days ago
  ```
- Requirements:
  - VM must be running
  - QEMU Guest Agent must be installed and running in the VM
  - Command execution permissions must be enabled in the Guest Agent
- Error Handling:
  - Returns error if VM is not running
  - Returns error if VM is not found
  - Returns error if command execution fails
  - Includes command output even if command returns non-zero exit code

### execute_container_command
Execute a command in an LXC container via SSH and pct exec.

- Parameters:
  - `node` (string, required): Name of the node where container is running
  - `vmid` (string, required): ID of the container
  - `command` (string, required): Command to execute
- Example Response:
  ```
  ğŸ”§ Container Command Result
    â€¢ Status: SUCCESS
    â€¢ Command: systemctl status redis
    â€¢ Node: pve-compute-01
    â€¢ Container: prod-redis (ID: 200)

  Output:
  â— redis-server.service - Advanced key-value store
     Loaded: loaded (/lib/systemd/system/redis-server.service; enabled)
     Active: active (running) since Mon 2025-01-15 10:23:45 UTC; 1 month ago
  ```
- Requirements:
  - Container must be running
  - SSH configuration must be provided in config
  - SSH access to the Proxmox host
- Error Handling:
  - Returns error if container is not running
  - Returns error if SSH connection fails
  - Returns error if container is not found
  - Includes command output even if command returns non-zero exit code

### execute_host_command
Execute a command directly on the Proxmox host via SSH.

- Parameters:
  - `node` (string, required): Name of the target node
  - `command` (string, required): Command to execute
- Example Response:
  ```
  ğŸ”§ Host Command Result
    â€¢ Status: SUCCESS
    â€¢ Command: pct list
    â€¢ Node: pve-compute-01

  Output:
  VMID       Status     Lock         Name
  200        running                 prod-redis
  201        stopped                 dev-database
  ```
- Use Cases:
  - Container management: `pct start 200`, `pct stop 200`, `pct reboot 200`
  - VM management: `qm start 100`, `qm stop 100`, `qm reboot 100`
  - System monitoring: `pvesh get /nodes/NODE/status`
- Requirements:
  - SSH configuration must be provided in config
  - SSH access to the Proxmox host
- Error Handling:
  - Returns error if SSH connection fails
  - Returns error if node is not found
  - Includes command output even if command returns non-zero exit code

## ğŸ‘¨â€ğŸ’» Development

After activating your virtual environment:

- Run tests: `pytest`
- Format code: `black .`
- Type checking: `mypy .`
- Lint: `ruff .`

## ğŸ“ Project Structure

```
proxmox-mcp/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ proxmox_mcp/
â”‚       â”œâ”€â”€ server.py          # Main MCP server implementation
â”‚       â”œâ”€â”€ config/            # Configuration handling
â”‚       â”œâ”€â”€ core/              # Core functionality (Proxmox API, logging)
â”‚       â”œâ”€â”€ formatting/        # Output formatting and themes
â”‚       â”œâ”€â”€ tools/             # Tool implementations
â”‚       â”‚   â”œâ”€â”€ console/       # VM/container console operations
â”‚       â”‚   â”œâ”€â”€ cluster.py     # Cluster management tools
â”‚       â”‚   â”œâ”€â”€ container.py   # LXC container tools
â”‚       â”‚   â”œâ”€â”€ node.py        # Node management tools
â”‚       â”‚   â”œâ”€â”€ storage.py     # Storage management tools
â”‚       â”‚   â””â”€â”€ vm.py          # Virtual machine tools
â”‚       â””â”€â”€ utils/             # Utilities (auth, logging)
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ proxmox-config/
â”‚   â””â”€â”€ config.example.json    # Configuration template
â”œâ”€â”€ run-server.sh             # Server startup script
â”œâ”€â”€ requirements*.in          # Dependency files
â”œâ”€â”€ uv.lock                   # UV lock file
â”œâ”€â”€ pyproject.toml            # Project metadata and dependencies
â””â”€â”€ LICENSE                   # MIT License
```

## ğŸ“„ License

MIT License
